{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desired_NumComments(n):\n",
    "    num = n/20\n",
    "    return math.ceil(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_comments(url, numScrollDowns):\n",
    "    data1=[]\n",
    "    data2=[]\n",
    "    # Warning: need to change the location of the path where you saved the chrome driver\n",
    "    with Chrome(executable_path=r'C:\\Program Files\\chromedriver.exe') as driver:\n",
    "        wait = WebDriverWait(driver,5)\n",
    "        driver.get(url)\n",
    "\n",
    "        # Scrolling down the page to load comments\n",
    "        for item in range(numScrollDowns): \n",
    "            wait.until(EC.visibility_of_element_located((By.TAG_NAME, \"body\"))).send_keys(Keys.END)\n",
    "            time.sleep(5)\n",
    "\n",
    "        # Scraping each author names\n",
    "        for body in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#author-text\"))):\n",
    "            data1.append(body.text)\n",
    "            \n",
    "        # Scraping each comments\n",
    "        for body in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#content-text\"))):\n",
    "            data2.append(body.text)\n",
    "\n",
    "    mergedData = ['&&&&&&'.join(x) for x in zip(data1,data2)]\n",
    "    return mergedData\n",
    "            \n",
    "# html key for the Id and the comment:\n",
    "# main\n",
    "# author-text\n",
    "# comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(scrapedData):\n",
    "    # Converting a list to dataframe\n",
    "    df = pd.DataFrame(scrapedData, columns=['chunk'])\n",
    "\n",
    "    # Adding column names\n",
    "    df[['User ID','Comment']] = df['chunk'].str.split(\"&&&&&&\",expand=True,)\n",
    "\n",
    "    # Replacing values & Dropping columns\n",
    "    df = df.drop(columns=['chunk'])\n",
    "    \n",
    "    # Saving the data as a csv file\n",
    "    df.to_csv('ScrapedYoutubeComment.csv', index=False)\n",
    "    print(\"Showing the first five comments\")\n",
    "    return df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and pase the url of the youtube video in the quotes\n",
    "url = \"https://www.youtube.com/watch?v=uJ7AfPrfqB0&ab_channel=FreeDocumentary-NatureFreeDocumentary-Nature\"\n",
    "\n",
    "# Input the desired number of comments you would like to scrape \n",
    "n = 221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing the first five comments\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Nameless Ones</td>\n",
       "      <td>38:51 i love how the penguin and a seal are ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jessica Liu</td>\n",
       "      <td>Teen penguins really look like kiwi fruits...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Max Naio</td>\n",
       "      <td>love this God bless whoever watching this in 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazing Wildlife Videos 2.0 with Shaun Etsebeth</td>\n",
       "      <td>Love this, wildlife is what i do. And this mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>upacara tujuh belasan Arifin</td>\n",
       "      <td>so many penguins can survive in the sea with b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           User ID  \\\n",
       "0                                The Nameless Ones   \n",
       "1                                      Jessica Liu   \n",
       "2                                         Max Naio   \n",
       "3  Amazing Wildlife Videos 2.0 with Shaun Etsebeth   \n",
       "4                     upacara tujuh belasan Arifin   \n",
       "\n",
       "                                             Comment  \n",
       "0  38:51 i love how the penguin and a seal are ju...  \n",
       "1      Teen penguins really look like kiwi fruits...  \n",
       "2  love this God bless whoever watching this in 2021  \n",
       "3  Love this, wildlife is what i do. And this mak...  \n",
       "4  so many penguins can survive in the sea with b...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numScrollDowns = desired_NumComments(n)\n",
    "scrapedData = scrape_comments(url, numScrollDowns)\n",
    "transform(scrapedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and pase the url of the youtube video in the quotes\n",
    "url = \"\"\n",
    "\n",
    "# Input the desired number of comments you would like to scrape \n",
    "n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell!\n",
    "numScrollDowns = desired_NumComments(n)\n",
    "scrapedData = scrape_comments(url, numScrollDowns)\n",
    "transform(scrapedData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
